spring.application.name=localchat
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2:latest
# Keep the same embedding model as used to create the vector store
spring.ai.ollama.embedding.options.model=nomic-embed-text

# Logging for debugging
logging.level.org.springframework.ai=DEBUG
logging.level.com.example.ai=DEBUG

# Server configuration
server.port=8081
server.error.include-message=always
server.error.include-binding-errors=always
